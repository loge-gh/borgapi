"""Option Dataclasses"""

import logging
import re
from dataclasses import dataclass
from typing import List, Optional, Union

logger = logging.getLogger(__name__)


@dataclass
class _DefaultField:
    """Field info in options classes"""

    name: str
    type: type
    default: object


@dataclass
class OptionsBase:
    """Holds all the shared methods for the subclasses

    Every subclass should use this __init__ method becuase it will only set the values that the
    dataclass supports and ignore the ones not part of it. This way the same options dict can be
    passed to every constructor and not have to worry about duplicating flags.
    """

    def __init__(self, **kwargs):
        default = self._defaults()
        for option in kwargs:
            if option in default:
                setattr(self, option, kwargs[option])

    @staticmethod
    def convert_name(value: str) -> str:
        """Add flag marker and replace underscores with dashes in name"""
        return "--" + value.replace("_", "-")

    def _field_set(self, field: str) -> bool:
        # pylint: disable=no-member
        default = self.__dataclass_fields__.get(field).default
        set_value = getattr(self, field)
        return set_value != default

    def _log_deprecated(self, old_field: str, new_field: str = None) -> None:
        if self._field_set(old_field):
            if new_field:
                logger.warning(
                    "[DEPRECATED] %s, use `%s` instead", old_field, new_field
                )
            else:
                logger.warning("[DEPRECATED] %s, not being replaced", old_field)

    # pylint: disable=no-member
    @classmethod
    def _defaults(cls) -> set[str]:
        defaults = set()
        for field in cls.__dataclass_fields__.values():
            defaults.add(field.name)
        return defaults

    def parse(self) -> List[Optional[Union[str, int]]]:
        """Turn options into list for argv

        :return: options for the command line
        :rtype: List[Optional[Union[str, int]]]
        """
        args = []
        # pylint: disable=no-member
        for key, value in self.__dataclass_fields__.items():
            attr = getattr(self, key)
            if attr is not None and value.default != attr:
                flag = self.convert_name(key)
                if value.type is bool:
                    if attr is not value.default:
                        args.append(flag)
                elif value.type is list:
                    for val in attr:
                        args.extend([flag, val])
                else:
                    args.extend([flag, attr])
        return args


# pylint: disable=too-many-instance-attributes
@dataclass
class CommonOptions(OptionsBase):
    """Common Options for all Borg commands

    :param critical: work on log level CRITICAL
    :type critical: bool
    :param error: work on log level ERROR
    :type error: bool
    :param warning: work on log level WARNING
    :type warning: bool
    :param info: work on log level INFO
    :type info: bool
    :param verbose: work on log level INFO
    :type verbose: bool
    :param debug: work on log level DEBUG
    :type debug: bool
    :param debug_topic: enable TOPIC debugging (can be specified multiple times). The logger path
        is borg.debug.<TOPIC> if TOPIC is not fully qualified.
    :type debug_topic: List[str]
    :param progress: show progress information
    :type progress: bool
    :param log_json: output one JSON object per log line instead of formatted text.
    :type log_json: bool
    :param lock_wait: wait at most SECONDS for acquiring a repository/cache lock (default: 1).
    :type lock_wait: int
    :param bypass_lock: bypass locking mechanism
    :type bypass_lock: bool
    :param show_version: show/log the borg version
    :type show_version: bool
    :param show_rc: show/log the return code (rc)
    :type show_rc: bool
    :param umask: set umask to M (local and remote, default: 0077)
    :type umask: str
    :param remote_path: use PATH as borg executable on the remote (default: “borg”)
    :type remote_path: str
    :param remote_ratelimit: set remote network upload rate limit in kiByte/s (default: 0=unlimited)
    :type remote_ratelimit: int
    :param consider_part_files: treat part files like normal files (e.g. to list/extract them)
    :type consider_part_files: bool
    :param debug_profile: write execution profile in Borg format into FILE. For local use a
        Python-compatible file can be generated by suffixing FILE with “.pyprof”
    :type debug_profile: str
    :param rsh: Use this command to connect to the ‘borg serve’ process (default: ‘ssh’)
    :type rsh: str
    """

    critical: bool = False
    error: bool = False
    warning: bool = False
    info: bool = False
    verbose: bool = False
    debug: bool = False
    debug_topic: List[str] = None
    progress: bool = False
    log_json: bool = False
    lock_wait: int = None
    bypass_lock: bool = False
    show_version: bool = False
    show_rc: bool = False
    umask: str = None
    remote_path: str = None
    remote_ratelimit: int = None
    consider_part_files: bool = False
    debug_profile: str = None
    rsh: str = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        if isinstance(self.debug_topic, str):
            self.exclude = [self.exclude]
        if self.umask and not re.match(r"^[0-9]{4}", self.umask):
            raise ValueError("umask must be in format 0000 permission code, eg: 0077")


@dataclass
class ExclusionOptions(OptionsBase):
    """Options for excluding various files from backup

    :param exclude: exclude paths matching PATTERN
    :type exclude: List[str]
    :param exclude_from: read exclude patterns from EXCLUDEFILE, one per line
    :type exclude_from: str
    :param pattern: include/exclude paths matching PATTERN (experimental)
    :type pattern: str
    :param patterns_from: read include/exclude patterns from PATTERNFILE, one per
        line (experimental)
    :type patterns_from: str
    """

    exclude: List[str] = None
    exclude_from: str = None
    pattern: List[str] = None
    patterns_from: str = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        if isinstance(self.exclude, str):
            self.exclude = [self.exclude]
        if isinstance(self.pattern, str):
            self.pattern = [self.pattern]


@dataclass
class ExclusionInput(ExclusionOptions):
    """Exclusion Options when inputing data to the archive

    :param exclude_caches: exclude directories that contain a CACHEDIR.TAG file
        (http://www.bford.info/cachedir/spec.html)
    :type exclude_caches: bool
    :param exclude_if_present: exclude directories that are tagged by containing a filesystem
        object with the given NAME
    :type exclude_if_present: List[str]
    :param keep_exclude_tags: if tag objects are specified with --exclude-if-present, don’t omit
        the tag objects themselves from the backup archive
    :type keep_exclude_tags: bool
    :param keep_tag_files: alternate to keep_exclude_tags
    :type keep_tag_files: bool
    :param exclude_nodump: exclude files flagged NODUMP
    :type exclude_nodump: bool
    """

    exclude_caches: bool = False
    exclude_if_present: List[str] = None
    keep_exclude_tags: bool = False
    keep_tag_files: bool = False
    exclude_nodump: bool = False

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        if isinstance(self.exclude_if_present, str):
            self.exclude_if_present = [self.exclude_if_present]


@dataclass
class ExclusionOutput(ExclusionOptions):
    """Exclusion Options when outputing data in the archive

    :param strip_componts: Remove the specified number of leading path elements. Paths with fewer
        elements will be silently skipped
    :type strip_componts: int
    """

    strip_componts: int = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


@dataclass
class FilesystemOptions(OptionsBase):
    """Options for how to handle filesystem attributes

    :param one_file_system: stay in the same file system and do not store mount points of other
        file systems. This might behave different from your expectations, see the docs.
    :type one_file_system: bool
    :param numeric_owner: only store numeric user and group identifiers
    :type numeric_owner: bool
    :param noatime: do not store atime into archive
    :type noatime: bool
    :param noctime: do not store ctime into archive
    :type noctime: bool
    :param nobirthtime: do not store birthtime (creation date) into archive
    :type nobirthtime: bool
    :param nobsdflags: do not read and store bsdflags (e.g. NODUMP, IMMUTABLE) into archive
    :type nobsdflags: bool
    :param noacls: do not read and store ACLs into archive
    :type noacls: bool
    :param noxattrs: do not read and store xattrs into archive
    :type noxattrs: bool
    :param ignore_inode: ignore inode data in the file metadata cache used to detect
        unchanged files.
    :type ignore_inode: bool
    :param files_cache: operate files cache in MODE. default: ctime,size,inode
    :type files_cache: str
    :param read_special: open and read block and char device files as well as FIFOs as if they were
        regular files. Also follows symlinks pointing to these kinds of files.
    :type read_special: bool
    """

    one_file_system: bool = False
    numeric_owner: bool = False
    noatime: bool = False
    noctime: bool = False
    nobirthtime: bool = False
    nobsdflags: bool = False
    noacls: bool = False
    noxattrs: bool = False
    ignore_inode: bool = False
    files_cache: str = None
    read_special: bool = False

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


@dataclass
class ArchiveOptions(OptionsBase):
    """Options related to the archive"""

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


@dataclass
class ArchiveInput(ArchiveOptions):
    """Archive Options when inputing data to the archive

    :param comment: add a comment text to the archive
    :type comment: str
    :param timestamp: manually specify the archive creation date/time
        (UTC, yyyy-mm-ddThh:mm:ss format). Alternatively, give a reference file/directory.
    :type timestamp: str
    :param checkpoint_interval: write checkpoint every SECONDS seconds (Default: 1800)
    :type checkpoint_interval: int
    :param chunker_params: specify the chunker parameters (CHUNK_MIN_EXP, CHUNK_MAX_EXP,
        HASH_MASK_BITS, HASH_WINDOW_SIZE). default: 19,23,21,4095
    :type chunker_params: str
    :param compression: select compression algorithm, see the output of the “borg help compression”
        command for details.
    :type compression: str
    """

    comment: str = None
    timestamp: str = None
    checkpoint_interval: int = None
    chunker_params: str = None
    compression: str = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


@dataclass
class ArchivePattern(ArchiveOptions):
    """Archive Options when outputing data in the archive

    :param prefix: only consider archive names starting with this prefix.
    :type prefix: str
    :param glob_archives: only consider archive names matching the glob.
        sh: rules apply, see “borg help patterns”. --prefix and --glob-archives
        are mutually exclusive.
    :type glob_archives: str
    """

    prefix: str = None
    glob_archives: str = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


@dataclass
class ArchiveOutput(ArchivePattern):
    """Archive options when filtering output

    :param sort_by: Comma-separated list of sorting keys; valid keys are: timestamp, name, id;
        default is: timestamp
    :type sort_by: str
    :param first: consider first N archives after other filters were applied
    :type first: int
    :param last: consider last N archives after other filters were applied
    :type last: int
    """

    sort_by: str = None
    first: int = None
    last: int = None

    # pylint: disable=useless-super-delegation
    def __init__(self, **kwargs):
        super().__init__(**kwargs)


class CommandOptions:
    """Optional Arguments for the different commands"""

    @dataclass
    class _InitOptional(OptionsBase):
        # create an append-only mode repository
        append_only: bool = False
        # set storage quota of the new repository (e.g. 5G, 1.5T)
        # default: no quota
        storage_quota: str = None
        # create the parent directories of the repository directory, if they are missing
        make_parent_dirs: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    # pylint: disable=too-many-instance-attributes
    @dataclass
    class _CreateOptional(OptionsBase):
        # do not create a backup archive
        dry_run: bool = False
        # print statistics for the created archive
        stats: bool = False
        # output verbose list of items (files, dirs, …)
        list: bool = False
        # only display items with the given status characters
        filter: str = None
        # output stats as JSON. Implies `stats`
        json: bool = False
        # experimental: do not synchronize the cache. Implies not using the files cache
        no_cache_sync: bool = False
        # do not load/update the file metadata cache used to detect unchanged files
        no_files_cache: bool = False
        # use NAME in archive for stdin data (
        # default: “stdin”
        stdin_name: str = None
        # set user USER in archive for stdin data
        # default: "root"
        stdin_user: str = None
        # set group GROUP in archive for stdin data
        # default: "root"
        stdin_group: str = None
        # set mode to M in archive for stdin data
        # default: 0660
        stdin_mode: str = None

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _ExtractOptional(OptionsBase):
        # output verbose list of items (files, dirs, …)
        list: bool = False
        # do not actually change any files
        dry_run: bool = False
        # only obey numeric user and group identifiers
        numeric_owner: bool = False
        # do not extract/set bsdflags (e.g. NODUMP, IMMUTABLE)
        nobsdflags: bool = False
        # do not extract/set ACLs
        noacls: bool = False
        # do not extract/set xattrs
        noxattrs: bool = False
        # write all extracted data to stdout
        stdout: bool = False
        # create holes in output sparse file from all-zero chunks
        sparse: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _CheckOptional(OptionsBase):
        # only perform repository checks
        repository_only: bool = False
        # only perform archives checks
        archives_only: bool = False
        # perform cryptographic archive data integrity verification
        # conflicts with `repository_only`
        verify_data: bool = False
        # attempt to repair any inconsistencies found
        repair: bool = False
        # work slower, but using less space
        save_space: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _ListOptional(OptionsBase):
        # only print file/directory names, nothing else
        short: bool = False
        # specify format for file listing
        # default: “{mode} {user:6} {group:6} {size:8d} {mtime} {path}{extra}{NL}”
        format: str = None
        # Only valid for listing repository contents. Format output as JSON.
        # The form of `format` is ignored, but keys used in it are added to the JSON output.
        # Some keys are always present.
        # Note: JSON can only represent text. A “barchive” key is therefore not available.
        json: bool = False
        # Only valid for listing archive contents. Format output as JSON lines.
        # The form of `format` is ignored, but keys used in it are added to the JSON output.
        # Some keys are always present.
        # Note: JSON can only represent text. A “bpath” key is therefore not available.
        json_lines: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _DiffOptional(OptionsBase):
        # only consider numeric user and group identifiers
        numeric_owner: bool = False
        # override check of chunker parameters
        same_chunker_params: bool = False
        # srt the output lines by file path
        sort: bool = False
        # format output as JSON lines
        json_lines: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

            self._log_deprecated("numeric_owner", "numeric_ids")

    @dataclass
    class _DeleteOptional(OptionsBase):
        # do not change repository
        dry_run: bool = False
        # print statistics for the deleted archive
        stats: bool = False
        # delete only the local cache for the given repository
        cache_only: bool = False
        # force deletion of corrupted archives
        force: bool = False
        # work slower, but using less space
        save_space: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    # pylint: disable=too-many-instance-attributes
    @dataclass
    class _PruneOptional(OptionsBase):
        # do not change repository
        dry_run: bool = False
        # force pruning of corrupted archives
        force: bool = False
        # print statistics for the deleted archive
        stats: bool = False
        # output verbose list of archives it keeps/prunes
        list: bool = False
        # keep all archives within this time interval
        keep_within: str = None
        # number of secondly archives to keep
        keep_last: int = None
        # number of secondly archives to keep
        keep_secondly: int = None
        # number of minutely archives to keep
        keep_minutely: int = None
        # number of hourly archives to keep
        keep_hourly: int = None
        # number of daily archives to keep
        keep_daily: int = None
        # number of weekly archives to keep
        keep_weekly: int = None
        # number of monthly archives to keep
        keep_monthly: int = None
        # number of yearly archives to keep
        keep_yearly: int = None
        # work slower, but using less space
        save_space: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _InfoOptional(OptionsBase):
        # format output as JSON
        json: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    # pylint: disable=invalid-name
    @dataclass
    class _MountOptional(OptionsBase):
        # stay in foreground, do not daemonize
        foreground: bool = False
        # extra mount options
        o: str = None

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _KeyExportOptional(OptionsBase):
        # create an export suitable for printing and later type-in
        paper: bool = False
        # create an html file suitable for printing and later type-in or qr scan
        qr_html: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _KeyImportOptional(OptionsBase):
        # interactively import from a backup done with `paper`
        paper: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _UpgradeOptional(OptionsBase):
        # do not change repository
        dry_run: bool = False
        # rewrite repository in place, with no chance of
        # going back to older versions of the repository
        inplace: bool = False
        # force upgrade
        force: bool = False
        # enable manifest authentication (in key and cache)
        tam: bool = False
        # disable manifest authentication (in key and cache)
        disable_tam: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _ExportTarOptional(OptionsBase):
        # filter program to pipe data through
        tar_filter: str = None
        # output verbose list of items (files, dirs, …)
        list: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _ServeOptional(OptionsBase):
        # restrict repository access to PATH. Can be specified multiple times to allow the client
        # access to several directories. Access to all sub-directories is granted implicitly;
        # PATH doesn’t need to directly point to a repository
        restrict_to_path: str = None
        # restrict repository access. Only the repository located at PATH (no sub-directories are
        # considered) is accessible. Can be specified multiple times to allow the client access to
        # several repositories. Unlike --restrict-to-path sub-directories are not accessible; PATH
        # needs to directly point at a repository location. PATH may be an empty directory or the
        # last element of PATH may not exist, in which case the client may initialize a
        # repository there
        restrict_to_repository: str = None
        # only allow appending to repository segment files
        append_only: bool = False
        # Override storage quota of the repository (e.g. 5G, 1.5T). When a new repository is
        # initialized, sets the storage quota on the new repository as well.
        # default: no quota
        storage_quota: str = None

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    @dataclass
    class _ConfigOptional(OptionsBase):
        # get and set values from the repo cache
        cache: bool = False
        # delete the key from the config file
        delete: bool = False
        # list the configuration of the repo
        list: bool = False

        # pylint: disable=useless-super-delegation
        def __init__(self, **kwargs):
            super().__init__(**kwargs)

    optional_classes = {
        "init": _InitOptional,
        "create": _CreateOptional,
        "extract": _ExtractOptional,
        "check": _CheckOptional,
        "list": _ListOptional,
        "diff": _DiffOptional,
        "delete": _DeleteOptional,
        "prune": _PruneOptional,
        "info": _InfoOptional,
        "mount": _MountOptional,
        "key_export": _KeyExportOptional,
        "key_import": _KeyImportOptional,
        "upgrade": _UpgradeOptional,
        "export_tar": _ExportTarOptional,
        "serve": _ServeOptional,
        "config": _ConfigOptional,
    }

    def __init__(self, defaults: dict = None):
        self.defaults = defaults or {}

    @classmethod
    def _get_optional(cls, command: str) -> OptionsBase:
        try:
            return cls.optional_classes[command]
        except KeyError as e:
            raise ValueError(
                f"Command `{command}` does not have any optional arguments or does not exist."
            ) from e

    def to_list(self, command: str, values: dict) -> list:
        """Return list with optional flags for command

        :param command: command being called
        :type command: str
        :param values: dictionary with values for flags
        :type values: dict
        :return: list of optional values converted to args list format
        :rtype: list
        """

        optionals = {**{self.defaults.get(command, {})}, **(values or {})}
        return self._get_optional(command)(**optionals).parse()
